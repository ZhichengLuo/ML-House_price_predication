{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "TRAIN_DATA_PATH = \"data/train.csv\"\n",
    "\n",
    "# load data\n",
    "df_train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "print(\"original shape : \" + str(df_train.shape))\n",
    "\n",
    "# remove id column\n",
    "df_train.drop('Id', axis=1, inplace=True)\n",
    "print(\"shape after dropping id : \" + str(df_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze target variable\n",
    "sns.distplot(df_train['SalePrice'])\n",
    "plt.show()\n",
    "\n",
    "print(df_train['SalePrice'].describe(), '\\n')\n",
    "print(\"Skewness: %f\" % df_train['SalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可选，看模型需要\n",
    "# log transformation on target variable\n",
    "# df_train['SalePrice'] = np.log1p(df_train['SalePrice'])\n",
    "# sns.distplot(df_train['SalePrice'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check outlier\n",
    "plt.scatter(df_train.GrLivArea, df_train.SalePrice, c = \"blue\", marker = \"s\")\n",
    "plt.title(\"Outliers\")\n",
    "plt.xlabel(\"GrLivArea\")\n",
    "plt.ylabel(\"SalePrice\")\n",
    "plt.show()\n",
    "\n",
    "# remove GrLivArea >= 4000 following https://ww2.amstat.org/publications/jse/v19n3/decock.pdf\n",
    "df_train = df_train[df_train.GrLivArea < 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing data\n",
    "missing_num = df_train.isnull().sum().sort_values(ascending=False)\n",
    "missing_percentage = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([missing_num, missing_percentage], axis=1, keys=['Missing num', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape before handling missing data : \", df_train.shape)\n",
    "\n",
    "# handle missing data\n",
    "# drop columns with too many missing values\n",
    "df_train = df_train.drop((missing_data[missing_data['Percent'] > 0.15]).index, 1)\n",
    "print(\"shape after dropping columns : \", df_train.shape)\n",
    "\n",
    "# drop rows with missing values because the small amount\n",
    "df_train = df_train.dropna()\n",
    "print(\"shape after dropping rows : \", df_train.shape)\n",
    "\n",
    "print('remaining null : ', df_train.isnull().sum().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation analysis\n",
    "corrmat = df_train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);\n",
    "plt.show()\n",
    "\n",
    "# look closer to top k correlated variables\n",
    "k = 10\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(df_train[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 纯可视化用，很慢所以先注释掉\n",
    "# scatterplot to visualize the correlation between variables\n",
    "# sns.set()\n",
    "# cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "# sns.pairplot(df_train[cols], size = 2.5)\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical to categorical\n",
    "df_train = df_train.replace(\n",
    "    {\n",
    "        \"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n",
    "                        50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n",
    "                        80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n",
    "                        150 : \"SC150\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n",
    "        \"MoSold\" :     {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n",
    "                        7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical to numerical as it indicates order\n",
    "df_train = df_train.replace(\n",
    "    {\n",
    "        \"BsmtCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "        \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n",
    "        \"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "        \"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "        \"BsmtQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "        \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "        \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "        \"FireplaceQu\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "        \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "        \"GarageCond\" : { \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "        \"GarageQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "        \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "        \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "        \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n",
    "        \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n",
    "        \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "        \"Utilities\" : {\"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiate numerical features, categorical features and target variable\n",
    "categorical_features = df_train.select_dtypes(include = [\"object\"]).columns\n",
    "numerical_features = df_train.select_dtypes(exclude = [\"object\"]).columns\n",
    "numerical_features = numerical_features.drop(\"SalePrice\")\n",
    "print(\"Numerical features : \" + str(len(numerical_features)))\n",
    "print(\"Categorical features : \" + str(len(categorical_features)))\n",
    "train_num = df_train[numerical_features]\n",
    "train_cat = df_train[categorical_features]\n",
    "y = df_train.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = train_num.skew()\n",
    "skewness = skewness[abs(skewness) > 0.5]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features\")\n",
    "skewed_features = skewness.index\n",
    "print(skewed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可选，看模型需要\n",
    "# Log transform of the skewed numerical features to lessen impact of outliers\n",
    "# Inspired by Alexandru Papiu's script : https://www.kaggle.com/apapiu/house-prices-advanced-regression-techniques/regularized-linear-models\n",
    "# As a general rule of thumb, a skewness with an absolute value > 0.5 is considered at least moderately skewed\n",
    "# skewness = train_num.skew()\n",
    "# skewness = skewness[abs(skewness) > 0.5]\n",
    "# print(str(skewness.shape[0]) + \" skewed numerical features\")\n",
    "# skewed_features = skewness.index\n",
    "# print(skewed_features)\n",
    "# train_num[skewed_features] = np.log1p(train_num[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可选，看模型需要\n",
    "# Create dummy features for categorical values via one-hot encoding\n",
    "# train_cat = pd.get_dummies(train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "df_train = pd.concat([train_num, train_cat, y], axis=1)\n",
    "df_train.to_csv(\"data/cleaned_train.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
